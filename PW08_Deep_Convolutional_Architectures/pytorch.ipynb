{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 MLP with PyTorch for CIFAR10\n",
    "\n",
    "Based on the notebooks provided and discussed during the lecture, set up a notebook for the configuration and training of a MLP on the CIFAR10 images.\n",
    "\n",
    "[These images](https://www.cs.toronto.edu/~kriz/cifar.html) of size 32x32 pixel show 10 different object categories\n",
    "\n",
    "Your implementation should provide the following features : \n",
    "\n",
    "- Download of the CIFAR10 images form an appropriate server and local storage for further usage.\n",
    "- Configuration of a custom Dataset (c.f. chapter 6.2.2 in the lecture notes) that will provide the CIFAR10 data to the DataLoader class during training.\n",
    "- Set up of a SummaryWriter for TensorBoard (c.f. chapter 6.2.3 in the lecture notes) and output of a set of CIFAR10 images (as grid like the figures above) to TensorBoard.\n",
    "- Set up of a MLP with confiigurable number of hidden layers that takes CIFAR10 (colour) images as input.\n",
    "- Preparation of the SummaryWriter for continuous output of training and validation loss/error to TensorBoard during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~ Imports ~~~\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~ PyTorch Lightning Data Module ~~~\n",
    "class CIFAR10DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=128):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Setup data only once per GPU\n",
    "        self.train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "        self.test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=20)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=20)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~ Transforms ~~~\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~ Builder Functions ~~~\n",
    "def conv_block(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(out_channels)\n",
    "    )\n",
    "\n",
    "def make_layers(in_channels, n_blocks=4, n_convs=3, out_channels=64, kernel_size=3, pool_size=2, dropout_rate=0.2):\n",
    "    layers = []\n",
    "    for _ in range(n_blocks):\n",
    "        for _ in range(n_convs):\n",
    "            layers.append(conv_block(in_channels, out_channels, kernel_size))\n",
    "            in_channels = out_channels  # Output becomes input for the next layer\n",
    "        layers.append(nn.MaxPool2d(kernel_size=pool_size, stride=pool_size))\n",
    "        layers.append(nn.Dropout(dropout_rate))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ~~~ Convolutional Neural Network ~~~\n",
    "class VGGNetPL(pl.LightningModule):\n",
    "    def __init__(self, in_channels=3, out_channels=64, n_blocks=4, n_convs=3, dropout_rate=0.2):\n",
    "        super(VGGNetPL, self).__init__()\n",
    "        self.features = make_layers(in_channels, n_blocks, n_convs, out_channels, dropout_rate=dropout_rate)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(out_channels * 2 * 2, 256),  # The 2*2 is derived assuming input is 32x32 and goes through four pooling layers\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log('val_loss', loss)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        self.log('test_loss', loss)\n",
    "        return {'test_loss': loss}\n",
    "\n",
    "\n",
    "    def configure_optimizers(self, learning_rate=0.001):\n",
    "        return optim.Adam(self.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~~~ Parameters ~~~\n",
    "batch_size = 512\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type             | Params\n",
      "------------------------------------------------\n",
      "0 | features   | Sequential       | 409 K \n",
      "1 | classifier | Sequential       | 68.4 K\n",
      "2 | criterion  | CrossEntropyLoss | 0     \n",
      "------------------------------------------------\n",
      "477 K     Trainable params\n",
      "0         Non-trainable params\n",
      "477 K     Total params\n",
      "1.912     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 98/98 [00:08<00:00, 11.36it/s, v_num=5]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 98/98 [00:08<00:00, 11.33it/s, v_num=5]\n"
     ]
    }
   ],
   "source": [
    "# ~~~ Setup training ~~~\n",
    "data_module = CIFAR10DataModule(batch_size=batch_size)\n",
    "model = VGGNetPL()\n",
    "model.configure_optimizers(learning_rate)\n",
    "logger = TensorBoardLogger('tb_logs', name='vgg_cifar10')\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=num_epochs, logger=logger, callbacks=[ModelCheckpoint(monitor=\"val_loss\")])\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 20/20 [00:00<00:00, 44.85it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5163008570671082\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.5163008570671082}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ~~~ Setup Evaluation ~~~\n",
    "trainer.test(model, datamodule=data_module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
